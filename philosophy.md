---
permalink: /philosophy/
---
# Philosophy

[Pereira (2017)](https://arxiv.org/abs/1705.03078) introduces the Super-Strong Self-Sampling Assumption (SSSSA) that human consciousness should be a typical sample in the consciousness-space-time. He then concludes that superintelligent AI would probably not be created because otherwise it would dominate the consciousness-space-time.

## Consciousness

[Friston (2017)](https://aeon.co/essays/consciousness-is-not-a-thing-but-a-process-of-inference) argues that consciousness is a process about inferring the causes of sensory states, and thereby navigating the world to elude surprises. We invoke this concept to describe a system when its internal model of self and the world has sufficient *counterfactural depth*, the temporal distance to the future on which the system can grasp the impact of its actions. Curiosity is not mentioned in this essay, and it is not clear how the curious behavior of seeking surprises can be reconciled with a disinterested mind. But it is conceivable that meaningful curiosity can be interpreted as the system acquiring information to reduce future uncertainty.

## References

* 2017 May 18, Karl Friston. [The mathematics of mind-time](https://aeon.co/essays/consciousness-is-not-a-thing-but-a-process-of-inference). *Aeon*.
* 2017 May 8, Toby Pereira. [An Anthropic Argument against the Future Existence of Superintelligent Artificial Intelligence](https://arxiv.org/abs/1705.03078). *arXiv:1705.03078*.
