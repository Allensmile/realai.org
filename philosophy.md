---
permalink: /philosophy/
mathjax: true
---
# Philosophy

[Pereira (2017)](https://arxiv.org/abs/1705.03078) introduces the Super-Strong Self-Sampling Assumption (SSSSA) that human consciousness should be a typical sample in the consciousness-space-time. He then concludes that superintelligent AI would probably not be created because otherwise it would dominate the consciousness-space-time.

## What Is Intelligence?

Many systems operating inside an environment exhibit a certain degree of complexity. Intelligence is such complexity as perceived by us. This definition is first of all subjective. Take the atmosphere for example, it is not considered intelligent today as we have already had a reasonably good understanding of atmospheric sciences. In ancient times, however, people resorted to myths for an explanation, implicitly assuming intelligence. Other examples include:

* AlphaGo ([Silver & Huang et al., 2016](http://www.nature.com/nature/journal/v529/n7587/full/nature16961.html)). It would be considered AI a few years before its development, but not so once the paper explaining its principles are published, as the readers can easily build a mental model of how it works.
* iPhone. Again it would be considered AI shortly around the years mobile phones were invented, but not so by the time it was in mass production.

It is safe to expect that humans will always be considered intelligent, but no lesser systems appear safe as the capability of machine intelligence steadily improves.

The scope of an AI system ranges from classical reinforcement learning agents that are individualistic with a stable boundary, to a distributed population of physical processes with a certain level of coordination. The latter end of the scope is explained more rigorously in [Weinbaum & Veitas (2015)](https://arxiv.org/abs/1505.06366). A distributed intelligence emerging from the Internet is called the [global brain](https://en.wikipedia.org/wiki/Global_brain) and is studied by [The Global Brain Institute](http://globalbraininstitute.org). The difference between open-ended and utility-based intelligence is discussed in [Goertzel (2015)](http://jetpress.org/v25.2/goertzel.htm), particularly its Section 9.

## Consciousness

[Friston (2017)](https://aeon.co/essays/consciousness-is-not-a-thing-but-a-process-of-inference) argues that consciousness is a process about inferring the causes of sensory states, and thereby navigating the world to elude surprises. We invoke this concept to describe a system when its internal model of self and the world has sufficient *counterfactural depth*, the temporal distance to the future on which the system can grasp the impact of its actions. Curiosity is not mentioned in this essay, and it is not clear how the curious behavior of seeking surprises can be reconciled with a disinterested mind. But it is conceivable that meaningful curiosity can be interpreted as the system acquiring information to reduce future uncertainty.

[Lawrence (2017)](https://arxiv.org/abs/1705.07996) suggests that we develop complex cognitive processes including consciousness as we make best use of the limited bandwidth for [communication](http://realai.org/multi-agent-learning/#communication). The *embodiment factor*, the ratio of compute power to communication bandwidth, is a distinguishing feature of human and current machine intelligence. A typical desktop computer today has an embodiment factor of around \\(10\\), while the huge processing power of human brain and the very low information rate of reading or talking yield an embodiment factor of around \\(10^{16}\\).

## References

* 2017 May 22, Neil D. Lawrence. [Living Together: Mind and Machine Intelligence](https://arxiv.org/abs/1705.07996). *arXiv:1705.07996*.
* 2017 May 18, Karl Friston. [The mathematics of mind-time](https://aeon.co/essays/consciousness-is-not-a-thing-but-a-process-of-inference). *Aeon*.
* 2017 May 8, Toby Pereira. [An Anthropic Argument against the Future Existence of Superintelligent Artificial Intelligence](https://arxiv.org/abs/1705.03078). *arXiv:1705.03078*.
* 2016 January 28, David Silver, Aja Huang, Chris J. Maddison, Arthur Guez, Laurent Sifre, George van den Driessche, Julian Schrittwieser, Ioannis Antonoglou, Veda Panneershelvam, Marc Lanctot, Sander Dieleman, Dominik Grewe, John Nham, Nal Kalchbrenner, Ilya Sutskever, Timothy Lillicrap, Madeleine Leach, Koray Kavukcuoglu, Thore Graepel, and Demis Hassabis. [Mastering the game of Go with deep neural networks and tree search](http://www.nature.com/nature/journal/v529/n7587/full/nature16961.html). *Nature*, 529(7587):484-489.
* 2015 November. Ben Goertzel. [Superintelligence: Fears, Promises and Potentials](http://jetpress.org/v25.2/goertzel.htm). *Journal of Evolution & Technology*, 24(2):55-87.
* 2015 June 12, David Weinbaum and Viktoras Veitas. [Open Ended Intelligence: The individuation of Intelligent Agents](https://arxiv.org/abs/1505.06366). *arXiv:1505.06366*.
