---
permalink: /safety/research-groups/
---
# AI Safety Research Groups

Many research groups that work on AI safety are connected with [effective altruism](http://realai.org/safety/effective-altruism/).

##### Machine Intelligence Research Institute

The [Machine Intelligence Research Institute](https://intelligence.org/) (MIRI) is a research nonprofit studying the mathematical underpinnings of intelligent behavior.

* [Publications](https://intelligence.org/all-publications/)
* [Team](https://intelligence.org/team/)

MIRI was founded in 2000 and was known as the Singularity Institute for Artificial Intelligence. It agreed to change name following Singularity University's [acquisition](http://singularityu.org/2012/12/09/singularity-university-acquires-the-singularity-summit/) of the Singularity Summit in December 2012, and [became](https://intelligence.org/2013/01/30/we-are-now-the-machine-intelligence-research-institute-miri/) MIRI the following January.

[Luke Muehlhauser](http://lukemuehlhauser.com/) became MIRI's Executive Director in 2011, and [left](https://intelligence.org/2015/05/06/a-fond-farewell-and-a-new-executive-director/) on 6 May 2015 to accept a research postion at [GiveWell](http://realai.org/safety/effective-altruism/#givewell-good-ventures-and-the-open-philanthropy-project). [Nate Soares](http://so8r.es/) has been MIRI's Executive Director since then.

##### [Future of Humanity Institute](https://www.fhi.ox.ac.uk/):

* [Publications](http://www.fhi.ox.ac.uk/publications/)
* [Team](https://www.fhi.ox.ac.uk/about/the-team/)

##### [Future of Life Institute](https://futureoflife.org/)

##### [UC Berkeley Center for Human-Compatible AI](http://humancompatible.ai/)

##### [Center for the Study of Existential Risk](http://cser.org/)

##### [Leverhulme Center for the Future of Intelligence](http://lcfi.ac.uk/)

##### [Foundational Research Institute](https://foundational-research.org/)

##### Center for Applied Rationality

[Center for Applied Rationality](http://rationality.org/) is a non-profit 501(c)(3) tax-exempt organization (EIN 45-3100226) in Berkeley, California. It was founded in 2012 and runs 4-day immersive workshops priced at [USD 3,900](http://rationality.org/workshops/faq#what-is-the-price-of-the-workshop) that might [not be a good fit](http://rationality.org/workshops/faq#who-shouldnt-attend-cfar-workshops) for people uncomfortable with extensive socialization. All their workshops [aim narrowly](http://rationality.org/about/mission#third-we-are-focused-specifically-on-existential-win-and-on-the-people-social-fabric-and-thinking-skills-that-might-most-help-with-that--we-see-ai-safety-as-especially-key-here) at: (a) AI safety directly; or (b) developing our rationality. [Participants below 18 years old are not allowed](http://rationality.org/workshops/faq#im-not-18-yet-can-i-still-attend) at their core workshops.
