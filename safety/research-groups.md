---
permalink: /safety/research-groups/
---
# AI Safety Research Groups

Many research groups that work on AI safety are connected with [effective altruism](http://realai.org/safety/effective-altruism/).

##### Machine Intelligence Research Institute

The [Machine Intelligence Research Institute](https://intelligence.org/) (MIRI) is a research nonprofit studying the mathematical underpinnings of intelligent behavior.

* [Publications](https://intelligence.org/all-publications/)
* [Team](https://intelligence.org/team/)

MIRI was founded in 2000 and was known as the Singularity Institute for Artificial Intelligence. It agreed to change name following Singularity University's [acquisition](http://singularityu.org/2012/12/09/singularity-university-acquires-the-singularity-summit/) of the Singularity Summit in December 2012, and [became](https://intelligence.org/2013/01/30/we-are-now-the-machine-intelligence-research-institute-miri/) MIRI the following January.

[Luke Muehlhauser](http://lukemuehlhauser.com/) became MIRI's Executive Director in 2011, and [left](https://intelligence.org/2015/05/06/a-fond-farewell-and-a-new-executive-director/) on 6 May 2015 to accept a research postion at [GiveWell](http://realai.org/safety/effective-altruism/#givewell-good-ventures-and-the-open-philanthropy-project). [Nate Soares](http://so8r.es/) has been MIRI's Executive Director since then.

In its [2017 Updates and Strategy](https://intelligence.org/2017/04/30/2017-updates-and-strategy/) published on 30 April 2017, MIRI researchers adjusted upwards their estimated probability of AGI’s being developed before 2035. Consequently, MIRI expected AGI would bear closer resemblance to present-day AI systems. It started [hiring software engineers](https://intelligence.org/2017/04/30/software-engineer-internship-staff-openings/).

##### Center for Applied Rationality

[Center for Applied Rationality](http://rationality.org/) (CFAR) is a non-profit 501(c)(3) tax-exempt organization (EIN 45-3100226) in Berkeley, California. Rationality here means [“actually trying to figure things out.”](http://rationality.org/about/mission) It runs 4-day immersive workshops priced at [USD 3,900](http://rationality.org/workshops/faq#what-is-the-price-of-the-workshop) that might [not be a good fit](http://rationality.org/workshops/faq#who-shouldnt-attend-cfar-workshops) for people uncomfortable with extensive socialization. All their workshops [aim narrowly](http://rationality.org/about/mission#third-we-are-focused-specifically-on-existential-win-and-on-the-people-social-fabric-and-thinking-skills-that-might-most-help-with-that--we-see-ai-safety-as-especially-key-here) at: (a) AI safety directly; or (b) developing our rationality. [Participants below 18 years old are not allowed](http://rationality.org/workshops/faq#im-not-18-yet-can-i-still-attend) at their core workshops.

CFAR was spun off from MIRI in 2012, with which it still shares an office. Its co-founders Anna Salamon (President & Chair of Board), Julia Galef (President), Michael "Valentine" Smith (Research), and Andrew Critch (Curriculum Developer) are on the current [team](http://rationality.org/about/team) of staff, contractors, adjunct instructors, staff alumni, and board of directors.

##### [Future of Humanity Institute](https://www.fhi.ox.ac.uk/):

* [Publications](http://www.fhi.ox.ac.uk/publications/)
* [Team](https://www.fhi.ox.ac.uk/about/the-team/)

##### [Future of Life Institute](https://futureoflife.org/)

##### [UC Berkeley Center for Human-Compatible AI](http://humancompatible.ai/)

##### [Center for the Study of Existential Risk](http://cser.org/)

##### Leverhulme Center for the Future of Intelligence

The [Leverhulme Center for the Future of Intelligence](http://lcfi.ac.uk/) was [launched](http://www.cam.ac.uk/research/news/the-future-of-intelligence-cambridge-university-launches-new-centre-to-study-ai-and-the-future-of) in December 2015 by the University of Cambridge, where it is also based at. It is funded by a £10 million grant from the [Leverhulme Trust](https://www.leverhulme.ac.uk/), and has a clear practical goal, "to work together to ensure that we humans make the best of the opportunities of artificial intelligence as it develops over coming decades." It runs a series of [projects](http://www.lcfi.ac.uk/projects/) on the nature and impact of AI. [Demis Hassabis](http://lcfi.ac.uk/about/people/demis-hassabis/), co-founder and CEO of DeepMind, currently sits on CFI's [international advisory board](http://lcfi.ac.uk/about/people/).

##### [Foundational Research Institute](https://foundational-research.org/)

## References

* 2016 December 13, Ben Henry. [2017 AI Risk Literature Review and Charity Comparison](http://effective-altruism.com/ea/14w/2017_ai_risk_literature_review_and_charity/). *Effective Altruism Forum*.
