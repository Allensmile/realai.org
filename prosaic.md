---
permalink: /prosaic/
---
# Prosaic AI

It seems increasingly plausible that high-level machine intelligence could be built by scaling up current methods in deep learning, without qualitatively new ideas about "how intelligence works" ([Christiano, 2016](https://ai-alignment.com/prosaic-ai-control-b959644d79c2)). Complex intelligent behavior can emerge from generic learning objectives when deep neural network-based models have sufficient learning capacity, and training data contains sufficient richness and diversity. Moreover, similar behavior is difficult to induce by explicit engineering in simple environments as solutions found are often idiosyncratic as they overfit the learning objectives. Under this premise, the improvement of engineering capability will lead to the creation of AGI.

## Progress

### Locomotion Behavior

In [Heess et al. (2017)](https://arxiv.org/abs/1707.02286), agents successfully learn complex locomotion behavior such as running, jumping, crouching and turning. The agents are trained with deliberately simple and generic reward functions, but over a wide range of environmental conditions. 

## Resources

* [Near-Term AI Safety](https://www.facebook.com/groups/771703926331579/) is a Facebook group in which topics related to prosaic AI are often discussed as it is one of the most plausible paths towards the creation of AGI in very near future.

## References

* 2017 July 07, Nicolas Heess, Dhruva TB, Srinivasan Sriram, Jay Lemmon, Josh Merel, Greg Wayne, Yuval Tassa, Tom Erez, Ziyu Wang, Ali Eslami, Martin Riedmiller, and David Silver. [Emergence of Locomotion Behaviours in Rich Environments](https://arxiv.org/abs/1707.02286). *arXiv:1707.02286*.

* 2016 Novenber 19, Paul Christiano. [Prosaic AI alignment](https://ai-alignment.com/prosaic-ai-control-b959644d79c2). *[AI Alignment](https://ai-alignment.com/)*.

* 2016 October 17, Nicolas Heess, Greg Wayne, Yuval Tassa, Timothy Lillicrap, Martin Riedmiller, and David Silver. [Learning and Transfer of Modulated Locomotor Controllers](https://arxiv.org/abs/1610.05182). *arXiv:1610.05182*.

