---
permalink: /symbol-grounding/
---
# Symbol Grounding

Language is a tool of communication in which words (symbols) trigger thoughts in the brains of the communicators. These thoughts are complex, vary across people, and contain a lot more information than can be practically encoded in the symbols. In order to use a language effectively, a computer system needs to ground its symbols into their semantic meanings that humans intuitively understand. This is called the symbol grounding problem ([Harnad 1990](http://www.sciencedirect.com/science/article/pii/0167278990900876)).

[Garnelo et al. (2016)](https://arxiv.org/abs/1609.05518) proposed an end-to-end reinforcement learning architecture where a neural back end must learn a symbolic representation of its raw data to communicate with the front end.

## References

* 2016 September 18, Marta Garnelo, Kai Arulkumaran, and Murray Shanahan. [Towards Deep Symbolic Reinforcement Learning](https://arxiv.org/abs/1609.05518). *arXiv:1609.05518*.
* 1990 June, Stevan Harnad. [The Symbol Grounding Problem](http://www.sciencedirect.com/science/article/pii/0167278990900876). *Physica D: Nonlinear Phenomena*, 42(1-3):335-346. [html](http://users.ecs.soton.ac.uk/harnad/Papers/Harnad/harnad90.sgproblem.html).
