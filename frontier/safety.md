---
permalink: /frontier/safety.html
---
# Safety

On this page, we consider how to ensure that the AI system we develop will benefit the whole world.

## Timeline

### News

* 2017 January 5-8, The [Future of Life Institute](https://futureoflife.org/) brought together a group of AI researchers and thought leaders for the [Beneficial AI 2017](https://futureoflife.org/bai-2017/) conference that developed [The Asilomar AI Principles](https://futureoflife.org/ai-principles/).
  * 2017 February 9, [Creating Human-level AI: How and When?](https://www.youtube.com/watch?v=V0aXMTpZTfc) *YouTube*.
  * 2017 February 2, [How to Keep Strong AI Safe and Beneficial](https://www.youtube.com/watch?v=UMq4BcRf-bY). *YouTube*.
  * ... more conference videos, posted on or before 2017 February 2.
  * 2017 January 30, [Should we be hooking up AI to our brains? New Asilomar principles urge caution](http://www.geekwire.com/2017/asilomar-ai-principles-caution/). *GeekWire*.
* 2015 July 1, Elon Musk-backed group gives $7M to explore AI risks. [*CNET*](https://www.cnet.com/news/musk-backed-ai-group-to-give-7m-on-artificial-intelligence-research/), [*FLI*](https://futureoflife.org/2015selection/).
* 2015 January 28, Bill Gates wrote that he is "concerned about super intelligence". [*BBC*](http://www.bbc.com/news/31047780), [*Reddit*](https://www.reddit.com/r/IAmA/comments/2tzjp7/hi_reddit_im_bill_gates_and_im_back_for_my_third/co3r3g8/).
* 2015 January 12, A group of scientists and entrepreneurs, including Elon Musk and Stephen Hawking, signed an open letter promising to ensure AI research benefits humanity. [*Daily Mail*](http://www.dailymail.co.uk/sciencetech/article-2907069/Don-t-let-AI-jobs-kill-Stephen-Hawking-Elon-Musk-sign-open-letter-warning-robot-uprising.html).
* 2014 December 2, Prof. Stephen Hawking told the BBC that the development of full AI "could spell the end of the human race". [*BBC*](http://www.bbc.com/news/technology-30290540).
* 2014 October 27, Elon Musk said AI is our "biggest existential threat". [*The Guardian*](https://www.theguardian.com/technology/2014/oct/27/elon-musk-artificial-intelligence-ai-biggest-existential-threat).

### Research

* 2016 June 21, Dario Amodei, Chris Olah, Jacob Steinhardt, Paul Christiano, John Schulman, and Dan Man√©. [Concrete Problems in AI Safety](https://arxiv.org/abs/1606.06565). *arXiv:1606.06565*.
* 2015 January 12, Stuart Russell, Daniel Dewey, and Max Tegmark. [Research Priorities for Robust and Beneficial Artificial Intelligence](https://futureoflife.org/data/documents/research_priorities.pdf). *Future of Life Institute*.
* 2014 September 3, Nick Bostrom. [Superintelligence: Paths, Dangers, Strategies](https://www.amazon.com/gp/product/0199678111/). *Oxford University Press*.

## Real AI

Safe and beneficial intelligence is everywhere: trees release oxygen, food is grown in fields, and grid transmits electricity. These systems follow physical laws and their natural behavior, complex but not goal-driven, safely provides enormous benefits to human society. Our long-term vision is to build more such intelligence. A smart planet that automatically produces almost everything we need is a great place. Everyone will live well and prosper.

A long version is [under development](http://realai.org/frontier/towards-safe-and-beneficial-intelligence.html).

### FAQ

##### What are the goals of your AI systems?

We do not plan to build goal-driven AI systems. Our AIs are complex systems whose behaviors are dictated by the laws of physics, not the optimization of specific goals. We just need the systems to behave nicely.

##### How do you specify human values and ethics to your AI systems?

Safe and beneficial intelligent systems do not have to understand human values or ethics, as in many real world examples, but if necessary, our AI systems will learn by themselves to ensure that their behaviours are aligned with us. 

##### Will AI systems self-modify?

Yes, self-modification is a common intelligent behaviour. Just like people study and exercise, intelligent AI systems self-modify when they anticipate safe and beneficial outcomes.

##### How can AI systems recognize when they are not operating normally?

How do people recognize when they're sick? AI systems can conduct self tests and rely on assessments from other AI systems.
