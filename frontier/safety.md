---
permalink: /frontier/safety.html
---
# Safety

On this page, we consider how to ensure that the AI system we develop will benefit the whole world.

## Timeline of References

### News

* 2017 January 5-8, The [Future of Life Institute](https://futureoflife.org/) brought together a group of AI researchers and thought leaders for the [Beneficial AI 2017](https://futureoflife.org/bai-2017/) conference that developed [The Asilomar AI Principles](https://futureoflife.org/ai-principles/).
* 2015 January 28, Bill Gates wrote that he is "concerned about super intelligence". [*BBC*](http://www.bbc.com/news/31047780), [*Reddit*](https://www.reddit.com/r/IAmA/comments/2tzjp7/hi_reddit_im_bill_gates_and_im_back_for_my_third/co3r3g8/).
* 2015 January 12, A group of scientists and entrepreneurs, including Elon Musk and Stephen Hawking, signed an open letter promising to ensure AI research benefits humanity. [*Daily Mail*](http://www.dailymail.co.uk/sciencetech/article-2907069/Don-t-let-AI-jobs-kill-Stephen-Hawking-Elon-Musk-sign-open-letter-warning-robot-uprising.html).
* 2014 December 2, Prof. Stephen Hawking told the BBC that the development of full AI "could spell the end of the human race". [*BBC*](http://www.bbc.com/news/technology-30290540).
* 2014 October 27, Elon Musk said AI is our "biggest existential threat". [*The Guardian*](https://www.theguardian.com/technology/2014/oct/27/elon-musk-artificial-intelligence-ai-biggest-existential-threat).

### Research

* 2016 June 21, Dario Amodei, Chris Olah, Jacob Steinhardt, Paul Christiano, John Schulman, and Dan Man√©. [Concrete Problems in AI Safety](https://arxiv.org/abs/1606.06565). *arXiv:1606.06565*.
* 2015 January 12, Stuart Russell, Daniel Dewey, and Max Tegmark. [Research Priorities for Robust and Beneficial Artificial Intelligence](https://futureoflife.org/data/documents/research_priorities.pdf). *Future of Life Institute*.
* 2008 January 25, Stephen M. Omohundro. [The Basic AI Drives](https://selfawaresystems.files.wordpress.com/2008/01/ai_drives_final.pdf). [*Self-Aware Systems*](https://selfawaresystems.com/).

## At Real AI

*Below is a summary of our current thinking. It will be updated from time to time as our understanding of AI safety continues to improve. Comments should be directed to [Jonathan Yan](mailto:jyan@realai.org)*.

Among all the systems our civilization depends on, the nature has the best record: Physics never fails. We're the only known advanced civilization in vast time and space that stretch trillions of miles and billions of years. We have always been able to find a way forward.

We will design our intelligent system to learn from the nature, understand the significance of our civilization, and facilitate its continued propserity.

In order to achieve that, our AI will not be a naively utility-maximizing agent. Its learning mechanism is not necessarily a set of rules designed from optimizing a particular function. It will learn to be the way forward, protecting us against existential risks such as climate change, biotech, nuclear disaster, and harmful AI systems, including itself if it so turns out.

### The Appearance of Goal-Driven Behavior

An AI system is a complex system inside some environment. In the long run it does not even need to have a stable boundary. In the short run, when we can approximately draw boundary to separate the system from the environment, the system performs computations on its input and produces output. The output and input are sometimes linked in a way with the appearance that the system is trying to optimize an internal goal, while in fact the system is merely following the rules set in the environment.

A tilting doll appears to have an internal goal of always standing up straight, but this goal is nowhere encoded inside the doll, it's just physics.

Our philosophy of designing a safe AI is to build a system that robustly translates natural input into beneficial behavior. This is not necessarily a goal encoded in the system itself, but will accurately depict the system's behavior as long as the system computes naturally. Our confidence in such a system will come from the reliability of physics and the exceptional track record that the nature has always been beneficial to our civilization.

*To be continued ...*
