---
permalink: /auxiliary-tasks/
---
# Auxiliary tasks

[Jaderberg & Mnih & Czarnecki et al. (2016)](https://arxiv.org/abs/1611.05397) introduced the **UNREAL** agent that optimizes the combined loss function of reinforcement learning and auxiliary control and reward tasks. The agent significantly outperformed the previous state-of-the-art on Atari. [Shelhamer et al. (2016)](https://arxiv.org/abs/1612.07307) showed that self-supervised pre-training on auxiliary losses also improves reinforcment learning.

## References

* 2016 December 21, Evan Shelhamer, Parsa Mahmoudieh, Max Argus, and Trevor Darrell. [Loss is its own Reward: Self-Supervision for Reinforcement Learning](https://arxiv.org/abs/1612.07307). *arXiv:1612.07307*.
* 2016 November 16, Max Jaderberg, Volodymyr Mnih, Wojciech Marian Czarnecki, Tom Schaul, Joel Z Leibo, David Silver, and Koray Kavukcuoglu. [Reinforcement Learning with Unsupervised Auxiliary Tasks](https://arxiv.org/abs/1611.05397). *arXiv:1611.05397*.
  * 2016 March 4. [modified version](https://openreview.net/forum?id=SJ6yPD5xg). *OpenReview*.
  * 2016 December 10, Kosuke Miyoshi. [replication using TensorFlow and DeepMind Lab](https://github.com/miyosuda/unreal). *GitHub*.
* 2016 November 11, Piotr Mirowski, Razvan Pascanu, Fabio Viola, Hubert Soyer, Andrew J. Ballard, Andrea Banino, Misha Denil, Ross Goroshin, Laurent Sifre, Koray Kavukcuoglu, Dharshan Kumaran, and Raia Hadsell. [Learning to Navigate in Complex Environments](https://arxiv.org/abs/1611.03673). *arXiv:1611.03673*.
* 2016 September 18, Guillaume Lample and Devendra Singh Chaplot. [Playing FPS Games with Deep Reinforcement Learning](https://arxiv.org/abs/1609.05521). *arXiv:1609.05521*.
